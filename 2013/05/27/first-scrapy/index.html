<!DOCTYPE html>
<html lang="zh-Hans">
  <head>
    
<meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>


<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">



  <meta name="description" content="Scrapy爬虫工具入门尝试"/>




  <meta name="keywords" content="coding, scrapy, python, I'M DURAN" />










  <link rel="alternate" href="/atom.xml" title="I'M DURAN">




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.png?v=2.6.0" />



<link rel="canonical" href="https://duran.im/2013/05/27/first-scrapy/"/>


<link rel="stylesheet" type="text/css" href="/css/style.css?v=2.6.0" />



  <link rel="stylesheet" type="text/css" href="/lib/fancybox/jquery.fancybox.css" />




  


  <script id="google_analytics">
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

        ga('create', 'UA-56488433-2', 'auto');
        ga('send', 'pageview');
  </script>


  <script id="baidu_push">
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>









    <title> Scrapy爬虫工具入门尝试 - I'M DURAN </title>
  </head>

  <body><div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/." class="logo">I'M DURAN</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>

<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    
      <a href="/">
        <li class="mobile-menu-item">
          
          
            首页
          
        </li>
      </a>
    
      <a href="/archives/">
        <li class="mobile-menu-item">
          
          
            归档
          
        </li>
      </a>
    
      <a href="/about">
        <li class="mobile-menu-item">
          
          
            关于
          
        </li>
      </a>
    
  </ul>
</nav>

    <div class="container" id="mobile-panel">
      <header id="header" class="header"><div class="logo-wrapper">
  <a href="/." class="logo">I'M DURAN</a>
</div>

<nav class="site-navbar">
  
    <ul id="menu" class="menu">
      
        <li class="menu-item">
          <a class="menu-item-link" href="/">
            
            
              首页
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/archives/">
            
            
              归档
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/about">
            
            
              关于
            
          </a>
        </li>
      
    </ul>
  
</nav>

      </header>

      <main id="main" class="main">
        <div class="content-wrapper">
          <div id="content" class="content">
            
  
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          Scrapy爬虫工具入门尝试
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          2013-05-27
        </span>
        
        
      </div>
    </header>

    
    
  <div class="post-toc" id="post-toc">
    <h2 class="post-toc-title">文章目录</h2>
    <div class="post-toc-content">
      <ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#目标网页"><span class="toc-text"> 目标网页</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#分析xpath"><span class="toc-text"> 分析xpath</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#爬虫编写"><span class="toc-text"> 爬虫编写</span></a></li></ol>
    </div>
  </div>


    <div class="post-content">
      
        <p><a href="http://scrapy.org/" target="_blank" rel="noopener">Scrapy</a>是一款纯Python爬虫框架，安装使用据说都很方便。作为一个编程白痴，一边看官方文档上手，一边恶补基础概念，遇到问题就用stackoverflow搜索，经过3天折腾终于基本实现了初步的抓取目标：抓取外交部某栏目下的某一篇新闻的所有正文文字，保存到本地。</p>
<a id="more"></a>
<h3 id="目标网页"><a class="markdownIt-Anchor" href="#目标网页"></a> 目标网页</h3>
<p><a href="http://www.fmprc.gov.cn/mfa_chn/wjdt_611265/fyrbt_611275/t1040553.shtml" target="_blank" rel="noopener">http://www.fmprc.gov.cn/mfa_chn/wjdt_611265/fyrbt_611275/t1040553.shtml</a></p>
<h3 id="分析xpath"><a class="markdownIt-Anchor" href="#分析xpath"></a> 分析xpath</h3>
<p>需要抓取的是文章标题、发表日期和正文，对应的xpath是:</p>
<p><strong>title：</strong><acronym>//div[@id=‘title’]/h2</acronym><br>
<strong>date：</strong><acronym>//div[@class=‘data’]</acronym><br>
<strong>content：</strong><acronym>//div[@id=‘doccontent’]</acronym></p>
<p>（chrome里选择的xpath是<acronym>//[@id=“title”]</acronym>，实际上还需要加上<strong>h2</strong>，导致我一开始抓不到标题）</p>
<h3 id="爬虫编写"><a class="markdownIt-Anchor" href="#爬虫编写"></a> 爬虫编写</h3>
<ul>
<li>
<p>首先新建一个项目<code>$ scrapy startproject fmprc</code></p>
</li>
<li>
<p>进入下一层fmprc_crawl目录里编辑items.py，定义需要抓取的内容，新建一个FmprcItem，包含三个目标：</p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">from scrapy.item import Item, Field</span><br><span class="line"></span><br><span class="line">class FmprcItem(Item):</span><br><span class="line">    title = Field()</span><br><span class="line">    date = Field()</span><br><span class="line">    content = Field()</span><br><span class="line">    pass</span><br></pre></td></tr></table></figure>
<ul>
<li>然后打开spiders文件夹，新建一个爬虫文件fmprc_spider.py，编辑：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">#一开始声明用utf-8好像没用</span><br><span class="line">#-- coding: utf-8 --#</span><br><span class="line"></span><br><span class="line">from scrapy.spider import BaseSpider</span><br><span class="line">from scrapy.selector import HtmlXPathSelector</span><br><span class="line">from fmprc_crawl.items import FmprcItem</span><br><span class="line">#最后用了这段指定encoding为utf-8的方法，搜了半天才找到</span><br><span class="line">import sys</span><br><span class="line">reload(sys)</span><br><span class="line">sys.setdefaultencoding(&apos;utf-8&apos;)</span><br><span class="line"></span><br><span class="line">class FmprcSpider(BaseSpider):</span><br><span class="line">    name = &quot;fmprc&quot;</span><br><span class="line">    allowed_domains = [&quot;fmprc.gov.cn&quot;]</span><br><span class="line">    start_urls = [&quot;http://www.fmprc.gov.cn/mfa_chn/wjdt_611265/</span><br><span class="line">fyrbt_611275/t1040553.shtml&quot;]</span><br><span class="line"></span><br><span class="line">	def parse(self, response):</span><br><span class="line">    hxs = HtmlXPathSelector(response)</span><br><span class="line">    items = []</span><br><span class="line">    item = FmprcItem()</span><br><span class="line">    item[&apos;title&apos;] = hxs.select(&apos;//div[@class=&apos;view&apos;]/h2/text()&apos;).extract()</span><br><span class="line">    item[&apos;date&apos;] = hxs.select(&apos;//div[@id=&apos;time&apos;]/text()&apos;).extract()</span><br><span class="line">    item[&apos;content&apos;] = hxs.select(&apos;//div[@id=&apos;doccontent&apos;]//text()&apos;).extract()</span><br><span class="line">    #注意这里是&apos;//text&apos;双斜杠才能抓完所有的文本，否则selector会忽视内层tag里的文本</span><br><span class="line">    items.append(item)</span><br><span class="line">    return items</span><br></pre></td></tr></table></figure>
<ul>
<li>最后执行爬虫 <code>$ scrapy crawl fmprc</code></li>
</ul>
<p>没有错误的话，会返回unicode形式的抓取结果，这不是我想要的，于是需要输出为csv：</p>
<p><code>$ scrapy crawl -o 2013515.csv -t csv fmprc</code></p>
<p><em>参数：<code>-o</code> 输出的文件名 <code>-t</code> 输出的格式</em></p>
<p>虽然输出的结果格式很简陋，至此算是完成了爬虫的第一次尝试。</p>

      
    </div>

    
      
      

  <div class="post-copyright">
    <p class="copyright-item">
      <span>原文作者: </span>
      <a href="https://duran.im">cress</a>
    </p>
    <p class="copyright-item">
      <span>原文链接: </span>
      <a href="https://duran.im/2013/05/27/first-scrapy/">https://duran.im/2013/05/27/first-scrapy/</a>
    </p>
    <p class="copyright-item">
      <span>许可协议: </span>
      
      <a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/" target="_blank">知识共享署名-非商业性使用 4.0 国际许可协议</a>
    </p>
  </div>



      
      
  <div class="post-reward">
    <input type="checkbox" name="reward" id="reward" hidden />
    <label class="reward-button" for="reward">赞赏支持</label>
    <div class="qr-code">
      
      
        <label class="qr-code-image" for="reward">
          <img class="image" src="http://7qn9uj.com1.z0.glb.clouddn.com/cress-rewardQR-wx.jpg" title="wechat">
        </label>
      
      
    </div>
  </div>

    

    
      <footer class="post-footer">
        
          <div class="post-tags">
            
              <a href="/tags/coding/">coding</a>
            
              <a href="/tags/scrapy/">scrapy</a>
            
              <a href="/tags/python/">python</a>
            
          </div>
        
        
        
  <nav class="post-nav">
    
      <a class="prev" href="/2013/10/29/meowtaro-bedtime-story/">
        <i class="iconfont icon-left"></i>
        <span class="prev-text nav-default">喵太郎的睡前故事(1)</span>
        <span class="prev-text nav-mobile">上一篇</span>
      </a>
    
    
      <a class="next" href="/2012/09/13/if-i-cannot-hear/">
        <span class="next-text nav-default">如果我听不见了</span>
        <span class="prev-text nav-mobile">下一篇</span>
        <i class="iconfont icon-right"></i>
      </a>
    
  </nav>

      </footer>
    

  </article>


          </div>
          
  <div class="comments" id="comments">
    
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    
  </div>


        </div>
      </main>

      <footer id="footer" class="footer">

  <div class="social-links">
    
      
        
          <a href="mailto:cress@duran.im" class="iconfont icon-email" title="email"></a>
        
      
    
      
    
      
        
          <a href="https://twitter.com/supercress" class="iconfont icon-twitter" title="twitter"></a>
        
      
    
      
    
      
    
      
    
      
        
          <a href="https://github.com/cresstoo" class="iconfont icon-github" title="github"></a>
        
      
    
      
    
      
    
      
    
      
    
      
    
      
        
          <a href="https://instagram.com/kuresu" class="iconfont icon-instagram" title="instagram"></a>
        
      
    
    
    
      <a href="/atom.xml" class="iconfont icon-rss" title="rss"></a>
    
  </div>


<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://hexo.io/">Hexo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/ahonn/hexo-theme-even">Even</a>
  </span>

  <span class="copyright-year">
    
    &copy; 
     
      2004 - 
    
    2020

    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">cress</span>
  </span>
</div>

      </footer>

      <div class="back-to-top" id="back-to-top">
        <i class="iconfont icon-up"></i>
      </div>
    </div>

    
  
  <script type="text/javascript">
    var disqus_config = function () {
        this.page.url = 'https://duran.im/2013/05/27/first-scrapy/';
        this.page.identifier = '2013/05/27/first-scrapy/';
        this.page.title = 'Scrapy爬虫工具入门尝试';
    };
    (function() {
    var d = document, s = d.createElement('script');

    s.src = '//imduran.disqus.com/embed.js';

    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
    })();  
  </script>

  

  



    
  





  
    <script type="text/javascript" src="/lib/jquery/jquery-3.1.1.min.js"></script>
  

  
    <script type="text/javascript" src="/lib/slideout/slideout.js"></script>
  

  
    <script type="text/javascript" src="/lib/fancybox/jquery.fancybox.pack.js"></script>
  


    <script type="text/javascript" src="/js/src/even.js?v=2.6.0"></script>
<script type="text/javascript" src="/js/src/bootstrap.js?v=2.6.0"></script>

  </body>
</html>
